{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prospective-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable overly verbose tensorflow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Flatten, Conv2D, MaxPool2D, Reshape\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "# unused for now, to be used for ROC analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "allow_growth = True\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-buying",
   "metadata": {},
   "source": [
    "# Initialize the MobileNetV2 model for fine-tuning on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_96 (Functio (None, 3, 3, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "\n",
    "input = Input(input_shape)\n",
    "\n",
    "# get the pretrained model, cut out the top layer\n",
    "pretrained = MobileNetV2(input_shape=input_shape, include_top=False, weights= None)\n",
    "\n",
    "# if the pretrained model it to be used as a feature extractor, and not for\n",
    "# fine-tuning, the weights of the model can be frozen in the following way\n",
    "# for layer in pretrained.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "output = pretrained(input)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "# note the lower lr compared to the cnn example\n",
    "model.compile(SGD(lr=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print a summary of the model on screen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-delivery",
   "metadata": {},
   "source": [
    "# Get the datagenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "running-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train+val', 'train')\n",
    "     valid_path = os.path.join(base_dir, 'train+val', 'valid')\n",
    "\t \n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sudden-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get the data generators\n",
    "train_gen, val_gen = get_pcam_generators(r'C:\\Users\\20153761\\Documents\\TUe\\4e jaar\\3e kwartiel\\BIA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-purpose",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "multiple-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20153761\\Anaconda3\\envs\\8p361\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 72s 278ms/step - loss: 0.6367 - accuracy: 0.6574 - val_loss: 0.6932 - val_accuracy: 0.5063\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69324, saving model to tranfer_4.2_None_model_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 52s 232ms/step - loss: 0.5427 - accuracy: 0.7484 - val_loss: 0.6935 - val_accuracy: 0.4913\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69324\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 52s 232ms/step - loss: 0.4957 - accuracy: 0.7678 - val_loss: 0.6936 - val_accuracy: 0.5013\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69324\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 47s 209ms/step - loss: 0.4622 - accuracy: 0.7881 - val_loss: 0.6909 - val_accuracy: 0.5350\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69324 to 0.69094, saving model to tranfer_4.2_None_model_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 46s 206ms/step - loss: 0.4358 - accuracy: 0.8077 - val_loss: 0.6934 - val_accuracy: 0.5075\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69094\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 47s 207ms/step - loss: 0.4120 - accuracy: 0.8147 - val_loss: 0.6988 - val_accuracy: 0.5088\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.69094\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 47s 208ms/step - loss: 0.4357 - accuracy: 0.8048 - val_loss: 0.6954 - val_accuracy: 0.5225\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69094\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.4011 - accuracy: 0.8239 - val_loss: 0.7108 - val_accuracy: 0.4913\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69094\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 45s 200ms/step - loss: 0.4046 - accuracy: 0.8165 - val_loss: 0.6940 - val_accuracy: 0.4950\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69094\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 43s 192ms/step - loss: 0.4074 - accuracy: 0.8211 - val_loss: 0.6986 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.69094\n"
     ]
    }
   ],
   "source": [
    "allow_growth = True\n",
    "\n",
    "# save the model and weights\n",
    "model_name = 'tranfer_4.2_None_model'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model, note that we define \"mini-epochs\"\n",
    "train_steps = train_gen.n//train_gen.batch_size//20\n",
    "val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "# since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "# not used during training\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-format",
   "metadata": {},
   "source": [
    "### View loss graph\n",
    "````bash\n",
    "activate 8p361\n",
    "cd 'path/where/logs/are'\n",
    "tensorboard --logdir logs\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-library",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
